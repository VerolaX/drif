# Dynamic Robot Instruction Following
Machine learning system for following natural language navigation instructions on a real quadcopter. Demo video of the system following an instruction and building internal environment representations in the process:

[<img src="http://www.cs.cornell.edu/~valts/img/corl19_demo_video_thumbnail.png" alt="drawing" width="800"/>](https://www.youtube.com/watch?v=hbeU64UX3CM)

For full details of how the system works, please refer to the [paper](http://www.cs.cornell.edu/~valts/docs/blukis_corl19.pdf).

**This is the new CoRL 2019 branch for the physical quadcopter implementation with SuReAL. You may switch to the corl2018 branch to access the previous version. Code will be published here soon.**

### Intro
This is the code repository for the paper:
"[Learning to Map Natural Language Instructions to Physical Quadcopter Control using Simulated Flight](http://www.cs.cornell.edu/~valts/docs/blukis_corl19.pdf)", Valts Blukis, Yannick Terme, Eyvind Niklasson, Ross A. Knepper, and Yoav Artzi (CoRL 2019).

If you need help running the experiments in this repository, please don't hesitate to [contact me](http://www.cs.cornell.edu/~valts).

### What can it do?

The full set of videos from the evaluation run for which we report performance can be found [here](https://drive.google.com/drive/folders/1WPRGLFLhHsxxXVd3ykYQNea6kzn4-tVR?usp=sharing).

