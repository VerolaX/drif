# Dynamic Robot Instruction Following
### Coming soon! (or contact us now).
Sim-only implementation is available in branch corl2018.

Machine learning system for following natural language navigation instructions on a real quadcopter. Demo video explaining the system capabilities and structure is avaiable here:

[<img src="http://www.cs.cornell.edu/~valts/img/corl19_full_demo_video_thumbnail.png" alt="drawing" width="800"/>](https://www.youtube.com/watch?v=O7G0HYGqU4w)

Video visualizing all internal representations, including the semantic map, grounding map, and visitation distributions, is available here:

[<img src="http://www.cs.cornell.edu/~valts/img/corl19_repr_video_thumbnail.png" alt="drawing" width="600"/>](https://www.youtube.com/watch?v=d5rbCEcm4os)

For full details of how the system works, please refer to the [paper](http://www.cs.cornell.edu/~valts/docs/blukis_corl19.pdf).

### Intro
This is the code repository for the paper:
"[Learning to Map Natural Language Instructions to Physical Quadcopter Control using Simulated Flight](http://www.cs.cornell.edu/~valts/docs/blukis_corl19.pdf)", Valts Blukis, Yannick Terme, Eyvind Niklasson, Ross A. Knepper, and Yoav Artzi (CoRL 2019).

If you need help running the experiments in this repository, please don't hesitate to [contact me](http://www.cs.cornell.edu/~valts).

### What can it do?

The full set of videos from the evaluation run for which we report performance can be found [here](https://drive.google.com/drive/folders/1WPRGLFLhHsxxXVd3ykYQNea6kzn4-tVR?usp=sharing).

